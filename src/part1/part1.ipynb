{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca6aebf",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928f4af",
   "metadata": {},
   "source": [
    "## i \n",
    "<prev>__Получите аналитическое решение задачи регрессии, используя векторную форму уравнения__<prev>\n",
    "\n",
    "<Аналитическое решение изложено в фото в /src/part1/analytical_solution>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9660627f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\textit{W}_{opt} = (X^TX)^{-1}X^TY \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260a4955",
   "metadata": {},
   "source": [
    "## ii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae956b7",
   "metadata": {},
   "source": [
    "<prev>__Что меняется в решении при добавлении регуляризаций L1 и L2 к функции потерь?__\n",
    "\n",
    "Обычная функция потерь: \n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^n {L(y_i, f(x_i, \\theta))} \\to min \n",
    "\\end{align}\n",
    "$$\n",
    "C учетом регуляризацией:\n",
    "$$\n",
    "\\begin{align}\n",
    "min_\\theta\\sum_{i=1}^n {L(y_i, f(x_i, \\theta))} + \\lambda R(\\theta) \\tag{2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Функция ошибок с регуляризацией по норме L1 (Lasso): \n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^n {L(y_i, f(x_i, \\theta))} + \\lambda \\sum_{j=1}^m {|a_j|} \\to min  \\tag{3}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Функция ошибок с регуляризацией по норме L2 (Ridge): \n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^n {L(y_i, f(x_i, \\theta))} + \\lambda \\sum_{j=1}^m {a_j^2} \\to min \\tag{4}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab2e9f",
   "metadata": {},
   "source": [
    "Параметр penalty в классе LogisticRegression определяет тип регуляризации. \n",
    "* __none__ - нет регуляризации\n",
    "* __L2__ - Евклидова норма $||x||_{L_2} = \\sqrt{(x^2_1 + x^2_2 + ... + x^2_i)}$\n",
    "* __L1__ - норма $||x||_{L_1} = ||x_1|| + ||x_2|| +  ... + ||x_i||$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e6584",
   "metadata": {},
   "source": [
    "## iii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e2fd8",
   "metadata": {},
   "source": [
    "<prev>__Объясните, почему для отбора признаков часто используется регуляризация L1. Почему после подгонки модели многие веса оказываются равными 0?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d7296",
   "metadata": {},
   "source": [
    "При регуляризации по L1 (3) решение ствновится разреженным - многие веса Wi = 0 (так как минимизируем абсолютные значения весов). Также помогает не только избежать переобучения (overfitting), но и автоматически отсеивать ненужные признаки. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a538e92",
   "metadata": {},
   "source": [
    "## iv\n",
    "<prev> __Объясните, как можно использовать те же модели (линейную регрессию, гребневую и т. д.), но сделать возможным подгонку нелинейных зависимостей__ <prev>\n",
    "\n",
    "Если атрибуты имеют нелинейную зависимость (например, $x_i * x_j$), то линейную регрессию или другую модель (на основе L1 или L2 нормы) можно использовать с добавлением новых атрибутов, выражающих эту нелинейную зависимость. Например,\n",
    "$$\n",
    "\\begin{align*}\n",
    "F(x_i) = w_0 + w_1x_1 + w_2x_2\n",
    "\\end{align*}\n",
    "$$\n",
    "Допусти, есть $x_1^2$ коррелирует с целевой переменной y, так что можно ввести новую фичу $x_3=x_1^2$ и новая модель будет иметь следующий вид: \n",
    "$$\n",
    "\\begin{align*}\n",
    "F(x_i) = w_0 + w_1x_1 + w_2x_2 + w_3x_3 = w_0 + w_1x_1 + w_2x_2 + w_3x_1^2\n",
    "\\end{align*}\n",
    "$$\n",
    "Таким образом модель регрессии может определять нелинейную зависимость\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
